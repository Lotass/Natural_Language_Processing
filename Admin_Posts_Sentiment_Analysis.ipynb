{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By previously investigating the Admin Posts dataset, In the [Interpreting the Relationship between Sentiment and Engagement](https://github.com/Lotass/Natural_Language_Processing) notebook. I discovered tha dependency between various independent variable and the Sentiment variable.\n",
    "\n",
    "So, I see that it is kind of __overhead__ to apply __NLP/ Word2vec Model__ on the Admin post text data to fit a model for __Sentiment Analysis__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Approach is as the following, I will build a __Kernel-SVM Model__ based on Independent variables that is highly correlated to the dependent variables then I will apply the Feature Extraction technique LDA to boost up the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# import dataset\n",
    "admin_posts = pd.read_excel(\"Hyundai_admin_post_data.xls\")\n",
    "admin_posts = admin_posts.reset_index()\n",
    "admin_posts.drop([\"index\",\"Post_id\",\"user_name\",\"creation_date\",\"creation_time\",\"month\",\"updated_date\",\n",
    "                  \"updated_time\",\"link\",\"picture\",\"user_id\",\"text\",\"type\",\"ontologies\",\"entities\",\"Total_Sentiment\"],\n",
    "                   axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = admin_posts.iloc[:,:].values # independent variables\n",
    "y = admin_posts.iloc[:,2].values # sentiment as dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type a list of each unique sentiment values and its frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-8: 1,\n",
       " -6: 1,\n",
       " -4: 4,\n",
       " -3: 1,\n",
       " -2: 11,\n",
       " -1: 8,\n",
       " 0: 156,\n",
       " 1: 21,\n",
       " 2: 43,\n",
       " 3: 21,\n",
       " 4: 12,\n",
       " 5: 3,\n",
       " 6: 2,\n",
       " 7: 5,\n",
       " 8: 3,\n",
       " 9: 2,\n",
       " 11: 2}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict((i, list(y).count(i)) for i in y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into training and test set with __60%__ Training and __40%__ Testing.\n",
    "** I tried to make the split 70% and 30% for training and testing but the current configuration drived better results **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, train_size=0.6,  random_state= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to do some __Feature Scaling__ to normalize the training data before applying the __LDA Feature Extraction__ technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eng.Adel\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x = StandardScaler()\n",
    "x_train = sc_x.fit_transform(x_train)\n",
    "x_test = sc_x.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply linear discriminant analysis __LDA__ to Extract the Features that most discriminate/ seperate the multiple class values of the __Sentiment__ dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eng.Adel\\Anaconda2\\lib\\site-packages\\sklearn\\discriminant_analysis.py:455: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\Eng.Adel\\Anaconda2\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda = LDA (n_components = 2)\n",
    "x_train = lda.fit_transform(x_train, y_train)\n",
    "x_test = lda.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will try to optimize the __hyperparameters__ of the __Kernel-SVM__ Algorithm using the __Grid Search__ Technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.957983193277 {'C': 1, 'gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "\n",
    "# possible hyperparameters\n",
    "c_values = [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100]\n",
    "gamma_values = [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100]\n",
    "\n",
    "# accuracy\n",
    "best_score = 0\n",
    "best_params = {'C': None, 'gamma': None}\n",
    "\n",
    "# Kernel SVM Hyperparameters optimization\n",
    "for c in c_values:\n",
    "    for gamma in gamma_values:\n",
    "        # train the model for every hyperparameter value pair\n",
    "        classifier = SVC(kernel = 'rbf', C = c, gamma = gamma)\n",
    "        #classifier = SVC(kernel = 'rbf', C = random.randint(0,9), gamma = random.randint(0,3))\n",
    "        classifier.fit(x_train, y_train)\n",
    "        score = classifier.score(x_test, y_test)\n",
    "        \n",
    "        # rate the accuracy of the model using each hyperparameter value pair\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_params['C'] =  c\n",
    "            best_params['gamma'] = gamma\n",
    "\n",
    "# best score\n",
    "print best_score, best_params "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the __Kernel-SVM__ with a __Gaussian Kernel__Nodel to the training data using the derived optimal values of __C__ and __gamma__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  0  0  0  0  0  0  8  0  4  1  1  0  1  2  0  0 -4  0  5  0  0  2  0  0\n",
      "  3  0  1  0  8  4  0  8  0  7  6  0  0  1  0 -1  0  2  2  4  0 -2  0  0  0\n",
      "  0  0  0  0  0  0  0  0  2  3  0  0  0  1  3  0  0  0  0 -2  1  0 -2  0  8\n",
      "  0  0  0  0  1  2  0  8 -1  2  7  0  0  0  0 -1  0  0  2  0  2  0  3  1  0\n",
      "  0  2  0  0  0  0  2  3  8 -2  0  0  0  0  0  2  2  3  0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "classifier = SVC(kernel = 'rbf', random_state = 0, C = 1, gamma = 0.01)\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# Predicting the test set sentiment values\n",
    "y_pred = classifier.predict(x_test)\n",
    "print y_pred "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the __Confusion matrix__ of the __Kernel-SVM__  Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  4  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  3  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 69  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  9  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 14  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  6  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  2  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  2  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  2  0  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By interpreting the __Confusion matrix__ diagonal that represents the __True Positive (TP)__ = 0+1+4+3+69+9+14+6+3+1+1+2+1+0+0 = __114__ that \n",
    "\n",
    "#### Calculate the precision, recall and F1_Score scores Using Confusion Matrix of a Multiclass Classification Problem\n",
    "True positive: diagonal position, cm(x, x).\n",
    "False positiv__Confusion matrix__: sum of column x (without main diagonal), sum(cm(:, x))-cm(x, x).\n",
    "False negative: sum of row x (without main diagonal), sum(cm(x, :), 2)-cm(x, x). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the __Kernel-SVM__  Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Kernel-SVM Accuracy = 95.798319 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred)*100   # 67.41573%\n",
    "print \"The Kernel-SVM Accuracy = %f\" % acc, \"%\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
